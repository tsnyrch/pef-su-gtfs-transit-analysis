{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸšŠ GTFS Transit Analysis Dashboard\n",
        "\n",
        "## Comprehensive Analysis of Public Transit Data\n",
        "\n",
        "This notebook demonstrates a complete analysis pipeline for GTFS (General Transit Feed Specification) data, including:\n",
        "\n",
        "- ğŸ“Š **Data Processing & Feature Engineering**\n",
        "- ğŸ—ºï¸ **Network Analysis & Routing Algorithms**\n",
        "- ğŸ¤– **Machine Learning for Delay Prediction**\n",
        "- ğŸ“ˆ **Demand Forecasting**\n",
        "- ğŸ“± **Interactive Visualizations & Dashboard**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ› ï¸ Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import sys\n",
        "from data_processing import GTFSProcessor\n",
        "from routing import TransitRouter\n",
        "from prediction import DelayPredictor, DemandForecaster\n",
        "from visualization import TransitVisualizer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import custom modules\n",
        "sys.path.append('../src')\n",
        "\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"âœ… All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‚ Data Loading and Initial Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize GTFS processor\n",
        "data_path = '../data'\n",
        "gtfs = GTFSProcessor(data_path)\n",
        "\n",
        "# Load all GTFS data files\n",
        "loaded_data = gtfs.load_data()\n",
        "\n",
        "print(f\"\\nğŸ“Š Loaded {len(loaded_data)} GTFS data files\")\n",
        "for name, df in loaded_data.items():\n",
        "    print(f\"  - {name}: {len(df):,} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get summary statistics\n",
        "stats = gtfs.get_summary_statistics()\n",
        "\n",
        "print(\"\\nğŸ“ˆ Dataset Summary:\")\n",
        "print(\"=\" * 40)\n",
        "for key, value in stats.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"{key}:\")\n",
        "        for k, v in value.items():\n",
        "            print(f\"  - {k}: {v}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Feature Engineering and Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create engineered features\n",
        "features_df = gtfs.create_features()\n",
        "\n",
        "# Display sample of engineered features\n",
        "print(\"\\nğŸ” Sample of Engineered Features:\")\n",
        "print(\"=\" * 50)\n",
        "display(features_df[[\n",
        "    'stop_id', 'trip_id', 'route_id', 'hour', 'is_rush_hour', \n",
        "    'time_period', 'route_type_name', 'is_first_stop', 'is_last_stop'\n",
        "]].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate travel times between stops\n",
        "travel_times_df = gtfs.calculate_travel_times()\n",
        "\n",
        "print(\"\\nâ±ï¸ Travel Time Analysis:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total segments analyzed: {len(travel_times_df):,}\")\n",
        "print(f\"Average travel time: {travel_times_df['travel_time_minutes'].mean():.2f} minutes\")\n",
        "print(f\"Average distance: {travel_times_df['distance_km'].mean():.2f} km\")\n",
        "print(f\"Average speed: {travel_times_df['speed_kmh'].mean():.2f} km/h\")\n",
        "\n",
        "# Display sample\n",
        "display(travel_times_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ºï¸ Network Analysis and Routing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize transit router\n",
        "router = TransitRouter(gtfs)\n",
        "\n",
        "# Build network graph\n",
        "network_graph = router.build_network(weight_type='travel_time')\n",
        "\n",
        "# Get network statistics\n",
        "network_stats = router.get_network_statistics()\n",
        "\n",
        "print(\"\\nğŸ•¸ï¸ Network Analysis Results:\")\n",
        "print(\"=\" * 40)\n",
        "for key, value in network_stats.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.3f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze network centrality\n",
        "centrality_measures = router.analyze_centrality(['degree', 'betweenness', 'closeness'])\n",
        "\n",
        "# Find most important stops\n",
        "print(\"\\nğŸ¯ Most Important Stops by Centrality:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for measure, values in centrality_measures.items():\n",
        "    if values:  # Check if values exist\n",
        "        top_stops = sorted(values.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        print(f\"\\n{measure.capitalize()} Centrality:\")\n",
        "        for i, (stop_id, score) in enumerate(top_stops, 1):\n",
        "            stop_name = \"Unknown\"\n",
        "            if gtfs.stops is not None:\n",
        "                stop_info = gtfs.stops[gtfs.stops['stop_id'] == stop_id]\n",
        "                if len(stop_info) > 0:\n",
        "                    stop_name = stop_info.iloc[0].get('stop_name', 'Unknown')\n",
        "            print(f\"  {i}. {stop_name} ({stop_id}): {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate shortest path finding\n",
        "if gtfs.stops is not None and len(gtfs.stops) > 1:\n",
        "    # Get two random stops for demonstration\n",
        "    stops = gtfs.stops['stop_id'].tolist()\n",
        "    start_stop = stops[0]\n",
        "    end_stop = stops[min(len(stops)-1, 10)]  # Pick a stop not too far for demo\n",
        "    \n",
        "    print(\"\\nğŸ¯ Shortest Path Analysis:\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"From: {start_stop}\")\n",
        "    print(f\"To: {end_stop}\")\n",
        "    \n",
        "    # Find shortest path\n",
        "    try:\n",
        "        path, cost = router.find_shortest_path(start_stop, end_stop)\n",
        "        if path:\n",
        "            print(\"\\nâœ… Path found!\")\n",
        "            print(f\"Number of stops: {len(path)}\")\n",
        "            print(f\"Total cost: {cost:.2f} minutes\")\n",
        "            print(f\"Path: {' â†’ '.join(path[:5])}{'...' if len(path) > 5 else ''}\")\n",
        "        else:\n",
        "            print(\"âŒ No path found between these stops\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error finding path: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– Machine Learning: Delay Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize delay predictor\n",
        "delay_predictor = DelayPredictor(gtfs)\n",
        "\n",
        "# Prepare training data (with simulated delays)\n",
        "training_data = delay_predictor.prepare_training_data(simulate_delays=True)\n",
        "\n",
        "print(\"\\nğŸ² Training Data for Delay Prediction:\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"Training samples: {len(training_data):,}\")\n",
        "print(f\"Features: {len([col for col in training_data.columns if col != 'delay_minutes'])}\")\n",
        "print(\"\\nDelay Statistics:\")\n",
        "print(f\"  Mean delay: {training_data['delay_minutes'].mean():.2f} minutes\")\n",
        "print(f\"  Median delay: {training_data['delay_minutes'].median():.2f} minutes\")\n",
        "print(f\"  Max delay: {training_data['delay_minutes'].max():.2f} minutes\")\n",
        "print(f\"  Min delay: {training_data['delay_minutes'].min():.2f} minutes\")\n",
        "\n",
        "# Show sample\n",
        "display(training_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the delay prediction model\n",
        "training_results = delay_predictor.train_model(training_data, model_type='random_forest')\n",
        "\n",
        "print(\"\\nğŸ¯ Model Training Results:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Training MAE: {training_results['train_mae']:.3f} minutes\")\n",
        "print(f\"Test MAE: {training_results['test_mae']:.3f} minutes\")\n",
        "print(f\"Training RMSE: {training_results['train_rmse']:.3f} minutes\")\n",
        "print(f\"Test RMSE: {training_results['test_rmse']:.3f} minutes\")\n",
        "print(f\"Training RÂ²: {training_results['train_r2']:.3f}\")\n",
        "print(f\"Test RÂ²: {training_results['test_r2']:.3f}\")\n",
        "print(f\"CV MAE: {training_results['cv_mae']:.3f} Â± {training_results['cv_mae_std']:.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "if 'feature_importance' in training_results:\n",
        "    print(\"\\nğŸ” Top 5 Most Important Features:\")\n",
        "    for i, feature in enumerate(training_results['feature_importance'][:5], 1):\n",
        "        print(f\"  {i}. {feature['feature']}: {feature['importance']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate delay prediction\n",
        "print(\"\\nğŸ”® Delay Prediction Examples:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create sample scenarios\n",
        "scenarios = [\n",
        "    {\n",
        "        'name': 'Morning Rush Hour - Bus',\n",
        "        'hour': 8,\n",
        "        'is_rush_hour': 1,\n",
        "        'route_type': 3,  # Bus\n",
        "        'stop_sequence': 5,\n",
        "        'weather_condition': 0  # Normal weather\n",
        "    },\n",
        "    {\n",
        "        'name': 'Midday - Subway',\n",
        "        'hour': 14,\n",
        "        'is_rush_hour': 0,\n",
        "        'route_type': 1,  # Subway\n",
        "        'stop_sequence': 10,\n",
        "        'weather_condition': 1  # Mild weather issues\n",
        "    },\n",
        "    {\n",
        "        'name': 'Evening Rush - Tram',\n",
        "        'hour': 18,\n",
        "        'is_rush_hour': 1,\n",
        "        'route_type': 0,  # Tram\n",
        "        'stop_sequence': 3,\n",
        "        'weather_condition': 2  # Severe weather\n",
        "    }\n",
        "]\n",
        "\n",
        "for scenario in scenarios:\n",
        "    prediction = delay_predictor.predict_delay(scenario)\n",
        "    print(f\"\\n{scenario['name']}:\")\n",
        "    print(f\"  Predicted delay: {prediction:.2f} minutes\")\n",
        "    print(f\"  Scenario: {scenario['hour']:02d}:00, Weather level: {scenario['weather_condition']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Demand Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize demand forecaster\n",
        "demand_forecaster = DemandForecaster(gtfs)\n",
        "\n",
        "# Simulate ridership data\n",
        "ridership_data = demand_forecaster.simulate_ridership_data(days=30)\n",
        "\n",
        "print(\"\\nğŸ“Š Ridership Data Simulation:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total records: {len(ridership_data):,}\")\n",
        "print(f\"Date range: {ridership_data['date'].min()} to {ridership_data['date'].max()}\")\n",
        "print(f\"Total ridership: {ridership_data['ridership'].sum():,}\")\n",
        "print(f\"Average daily ridership: {ridership_data.groupby('date')['ridership'].sum().mean():.0f}\")\n",
        "\n",
        "# Show sample\n",
        "display(ridership_data.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze demand patterns\n",
        "demand_patterns = demand_forecaster.get_demand_patterns()\n",
        "\n",
        "print(\"\\nğŸ“ˆ Demand Pattern Analysis:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Peak hours\n",
        "print(\"\\nğŸ• Peak Hours:\")\n",
        "for hour, ridership in demand_patterns['peak_hours'].items():\n",
        "    print(f\"  {hour}:00 - {ridership:.0f} average riders\")\n",
        "\n",
        "# Weekend vs weekday\n",
        "print(\"\\nğŸ“… Weekend vs Weekday:\")\n",
        "for is_weekend, ridership in demand_patterns['weekend_vs_weekday'].items():\n",
        "    day_type = \"Weekend\" if is_weekend else \"Weekday\"\n",
        "    print(f\"  {day_type}: {ridership:.0f} average riders\")\n",
        "\n",
        "# Top stops\n",
        "print(\"\\nğŸš Top 5 Busiest Stops:\")\n",
        "for i, (stop_id, total_ridership) in enumerate(list(demand_patterns['top_stops'].items())[:5], 1):\n",
        "    print(f\"  {i}. {stop_id}: {total_ridership:,.0f} total riders\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate ridership forecast\n",
        "forecast_data = demand_forecaster.forecast_ridership(forecast_days=7)\n",
        "\n",
        "print(\"\\nğŸ”® 7-Day Ridership Forecast:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Daily totals\n",
        "daily_forecast = forecast_data.groupby('date').agg({\n",
        "    'forecasted_ridership': 'sum',\n",
        "    'confidence_lower': 'sum',\n",
        "    'confidence_upper': 'sum'\n",
        "}).round(0)\n",
        "\n",
        "print(\"Daily Forecast Summary:\")\n",
        "display(daily_forecast)\n",
        "\n",
        "# Calculate forecast accuracy simulation\n",
        "total_forecast = daily_forecast['forecasted_ridership'].sum()\n",
        "avg_daily_forecast = daily_forecast['forecasted_ridership'].mean()\n",
        "print(f\"\\nTotal 7-day forecast: {total_forecast:,.0f} riders\")\n",
        "print(f\"Average daily forecast: {avg_daily_forecast:,.0f} riders\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Interactive Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize visualizer\n",
        "visualizer = TransitVisualizer(gtfs, router)\n",
        "\n",
        "print(\"ğŸ¨ Creating Interactive Visualizations...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create route analysis plots\n",
        "route_fig = visualizer.plot_route_analysis()\n",
        "route_fig.show()\n",
        "\n",
        "print(\"âœ… Route analysis visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create delay prediction visualizations\n",
        "delay_fig = visualizer.plot_delay_predictions(delay_predictor)\n",
        "delay_fig.show()\n",
        "\n",
        "print(\"âœ… Delay prediction visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create network map\n",
        "try:\n",
        "    network_map = visualizer.plot_network_map(interactive=True)\n",
        "    if network_map:\n",
        "        # Save map\n",
        "        network_map.save('../outputs/transit_network_map.html')\n",
        "        print(\"âœ… Interactive network map created and saved!\")\n",
        "        print(\"ğŸ“ Map saved as: ../outputs/transit_network_map.html\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Could not create interactive map (insufficient coordinate data)\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Map creation failed: {e}\")\n",
        "    print(\"Creating static network visualization instead...\")\n",
        "    visualizer.plot_network_map(interactive=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“± Comprehensive Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive interactive dashboard\n",
        "dashboard_fig = visualizer.create_interactive_dashboard(\n",
        "    delay_predictor=delay_predictor,\n",
        "    demand_forecaster=demand_forecaster\n",
        ")\n",
        "\n",
        "dashboard_fig.show()\n",
        "\n",
        "print(\"âœ… Comprehensive dashboard created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save dashboard as HTML\n",
        "try:\n",
        "    visualizer.save_dashboard_html(dashboard_fig, '../outputs/transit_dashboard.html')\n",
        "    print(\"ğŸ’¾ Dashboard saved successfully!\")\n",
        "    print(\"ğŸ“ Dashboard saved as: ../outputs/transit_dashboard.html\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not save dashboard: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Real-time Analysis Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate real-time analysis for current hour\n",
        "from datetime import datetime\n",
        "\n",
        "current_hour = datetime.now().hour\n",
        "print(f\"\\nâ° Real-time Analysis for {current_hour}:00\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Get routes with current delays\n",
        "current_delays = visualizer.find_route_with_delay(current_hour, delay_predictor)\n",
        "\n",
        "print(\"\\nğŸš¨ Routes with Highest Predicted Delays:\")\n",
        "for i, route_data in enumerate(current_delays[:5], 1):\n",
        "    route_id = route_data['route_id']\n",
        "    delay = route_data['predicted_delay']\n",
        "    category = route_data['delay_category']\n",
        "    \n",
        "    status_emoji = \"ğŸ”´\" if delay > 5 else \"ğŸŸ¡\" if delay > 2 else \"ğŸŸ¢\"\n",
        "    print(f\"  {i}. {status_emoji} {route_id}: {delay:.1f} min delay ({category})\")\n",
        "\n",
        "# Current ridership prediction\n",
        "current_ridership = demand_forecaster.get_demand_patterns()['hourly'].get(current_hour, 0)\n",
        "print(f\"\\nğŸ‘¥ Expected ridership this hour: {current_ridership:.0f} passengers\")\n",
        "\n",
        "# System performance summary\n",
        "avg_delay = np.mean([r['predicted_delay'] for r in current_delays])\n",
        "high_delay_routes = len([r for r in current_delays if r['predicted_delay'] > 5])\n",
        "\n",
        "print(\"\\nğŸ“Š System Performance Summary:\")\n",
        "print(f\"  Average delay: {avg_delay:.1f} minutes\")\n",
        "print(f\"  Routes with high delays: {high_delay_routes}/{len(current_delays)}\")\n",
        "print(f\"  Network connectivity: {'Good' if network_stats.get('is_connected', False) else 'Limited'}\")\n",
        "print(f\"  Total active routes: {len(gtfs.routes) if gtfs.routes is not None else 'Unknown'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“‹ Summary and Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nğŸ‰ GTFS Transit Analysis Complete!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\nğŸ“Š Key Findings:\")\n",
        "print(f\"  â€¢ Analyzed {stats.get('num_routes', 'N/A')} routes across {stats.get('num_stops', 'N/A')} stops\")\n",
        "print(f\"  â€¢ Network has {network_stats['num_nodes']} nodes and {network_stats['num_edges']} connections\")\n",
        "print(f\"  â€¢ Average travel time: {travel_times_df['travel_time_minutes'].mean():.1f} minutes\")\n",
        "print(f\"  â€¢ ML model accuracy: {training_results['test_r2']:.3f} RÂ²\")\n",
        "print(f\"  â€¢ 7-day ridership forecast: {total_forecast:,.0f} passengers\")\n",
        "\n",
        "print(\"\\nğŸ› ï¸ Generated Outputs:\")\n",
        "print(\"  â€¢ Interactive network map\")\n",
        "print(\"  â€¢ Delay prediction model\")\n",
        "print(\"  â€¢ Demand forecasting system\")\n",
        "print(\"  â€¢ Comprehensive dashboard\")\n",
        "print(\"  â€¢ Real-time analysis capability\")\n",
        "\n",
        "print(\"\\nğŸ¯ Use Cases Demonstrated:\")\n",
        "print(\"  â€¢ Route optimization\")\n",
        "print(\"  â€¢ Delay prediction and management\")\n",
        "print(\"  â€¢ Capacity planning\")\n",
        "print(\"  â€¢ Real-time passenger information\")\n",
        "print(\"  â€¢ Network performance monitoring\")\n",
        "\n",
        "print(\"\\nâœ¨ This analysis provides a foundation for:\")\n",
        "print(\"  ğŸ“ˆ Data-driven transit planning\")\n",
        "print(\"  ğŸ¤– Predictive maintenance\")\n",
        "print(\"  ğŸ‘¥ Passenger experience optimization\")\n",
        "print(\"  ğŸ“± Real-time information systems\")\n",
        "print(\"  ğŸŒ Sustainable transportation insights\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸšŠ Thank you for exploring GTFS Transit Analysis! ğŸšŠ\")\n",
        "print(\"=\" * 50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
